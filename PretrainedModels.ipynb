{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Flatten, Conv2D, BatchNormalization, Dropout, MaxPooling2D, Activation\n",
    "from keras.callbacks import  Callback, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import random\n",
    "import imageio\n",
    "import os\n",
    "import cv2\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "random.seed(42)\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# !wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
    "# !unzip -q '/content/nature_12K.zip'\n",
    "\n",
    "imgsize = 128\n",
    "\n",
    "\n",
    "# Load training and testing dataset\n",
    "def TestingData(DataAugumentationFlag, batch_size):\n",
    "  if DataAugumentationFlag:\n",
    "      datagen = ImageDataGenerator(\n",
    "                rotation_range=45, \n",
    "                width_shift_range=0.2, \n",
    "                height_shift_range=0.2,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.2, \n",
    "                horizontal_flip=True, \n",
    "                fill_mode='reflect',\n",
    "                rescale=1./255\n",
    "                )\n",
    "  else:\n",
    "      datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "  TrainData = datagen.flow_from_directory(\n",
    "              directory='/content/inaturalist_12K/train',\n",
    "              target_size = (imgsize,imgsize),\n",
    "              batch_size=batch_size,\n",
    "              class_mode=\"categorical\",\n",
    "              shuffle=True,\n",
    "              seed=22)\n",
    "\n",
    "  test_data = datagen.flow_from_directory(\n",
    "            directory='/content/inaturalist_12K/val',\n",
    "            target_size=(imgsize,imgsize),\n",
    "            batch_size=batch_size,\n",
    "            class_mode=\"categorical\",\n",
    "            shuffle=True,\n",
    "            seed=22)\n",
    "  return test_data, TrainData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test():\n",
    "    KernalSize = [(3,3),(3,3),(3,3),(3,3),(3,3)]\n",
    "    WeightDecay = 0\n",
    "    Dropout = 0.2\n",
    "    lr = 1e-4\n",
    "    activation = 'selu'\n",
    "    bs = 64\n",
    "    batchnorm = 'false'\n",
    "    filterorg = [32,64,64,128,128]\n",
    "    dataagumentationflag = 'true'\n",
    "    denselayer = 256\n",
    "    input_shape = (imgsize, imgsize, 3)\n",
    "    model = Sequential()\n",
    "    filter = filterorg\n",
    "    model.add(Conv2D(filters = filter[0], kernel_size = KernalSize[0],padding = 'same', \n",
    "                    input_shape = input_shape, kernel_regularizer=regularizers.l2(WeightDecay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(filters = filter[1], kernel_size = KernalSize[1],padding = 'same', \n",
    "                    input_shape = input_shape, kernel_regularizer=regularizers.l2(WeightDecay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "    model.add(Conv2D(filters = filter[2], kernel_size = KernalSize[2],padding = 'same', \n",
    "                    input_shape = input_shape, kernel_regularizer=regularizers.l2(WeightDecay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(filters = filter[3], kernel_size = KernalSize[3],padding = 'same', \n",
    "                    input_shape = input_shape, kernel_regularizer=regularizers.l2(WeightDecay)))\n",
    "    model.add(Activation('elu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters = filter[4], kernel_size = KernalSize[4],padding = 'same', \n",
    "                    input_shape = input_shape, kernel_regularizer=regularizers.l2(WeightDecay)))\n",
    "    model.add(Activation('elu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(denselayer, activation = activation, kernel_regularizer = regularizers.l2(WeightDecay)))\n",
    "    model.add(Dropout(Dropout))\n",
    "\n",
    "    model.add(Dense(10, activation = \"softmax\"))\n",
    "\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = 'adam', metrics=['accuracy'])\n",
    "    TrainData, test_data = TestingData(dataagumentationflag, bs)\n",
    "    model.fit(TrainData, epochs=1)\n",
    "    model.evaluate(test_data, batch_size = bs)\n",
    "    model.save(\"model-best.h5\")\n",
    "    return model\n",
    "\n",
    "model = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names = {0:'Amphibia', 1:'Animalia', 2:'Arachnida',3: 'Aves',4: 'Fungi',\n",
    "              5: 'Insecta', 6:'Mammalia', 7:'Mollusca', 8:'Plantae',9: 'Reptilia'}\n",
    "\n",
    "img_size = imgsize\n",
    "dir = '/content/inaturalist_12K/val'\n",
    "\n",
    "visuvalizationtestimages = []\n",
    "visuvalizationtruelabels = []\n",
    "\n",
    "\n",
    "for label, name in class_names.items():\n",
    "  list_images = os.listdir(dir+'/'+name)\n",
    "  res = []\n",
    "  for j in range(3):\n",
    "    dummy = random.randint(0, 199)\n",
    "    res.append(list_images[dummy])\n",
    "  for image_name in res:\n",
    "      image = imageio.imread(dir+'/'+name+'/'+image_name)\n",
    "      if np.ndim(image) == 3:\n",
    "        visuvalizationtestimages.append(cv2.resize(image, (img_size,img_size)))\n",
    "        visuvalizationtruelabels.append(class_names[label])\n",
    "\n",
    "visuvalizationtestimages = np.array(visuvalizationtestimages)\n",
    "visuvalizationtestimages = visuvalizationtestimages/255.0\n",
    "fig = plt.figure(figsize=(30,20))\n",
    "\n",
    "gs = gridspec.GridSpec(10, 3, width_ratios=[1, 1, 1], wspace=0.0, hspace=1.0, top=0.95, bottom=0.05, left=0.7, right=0.845) \n",
    "k = 0\n",
    "for i in range(10):\n",
    "    for j in range(3):\n",
    "      ax = plt.subplot(gs[i,j])\n",
    "      img = visuvalizationtestimages[k]\n",
    "      ax.imshow(img)\n",
    "      prediction = model.predict(img.reshape(1,imgsize, imgsize, 3))[0]\n",
    "      true_label = visuvalizationtruelabels[k]\n",
    "      k = k + 1\n",
    "      ax.axis('off')\n",
    "      ax.set_title(\"True Label: \" + true_label + \"\\nPredicted: \" + class_names[np.argmax(prediction)])\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('predictions.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for layer in model.layers:\n",
    "\tif 'conv' not in layer.name:\n",
    "\t\tcontinue\n",
    "\tfilters, biases = layer.get_weights()\n",
    "\tprint(layer.name, filters.shape)\n",
    "\n",
    "filters, biases = model.layers[0].get_weights()\n",
    "f_minimum, f_maximum = filters.min(), filters.max()\n",
    "filters = (filters - f_minimum) / (f_maximum - f_minimum)\n",
    "\n",
    "fig = plt.figure(figsize=(imgsize,imgsize))\n",
    "gs = gridspec.GridSpec(32, 3, width_ratios=[1, 1, 1], wspace=0.0, hspace=0.5, top=0.95, bottom=0.05, left=0.7, right=0.845) \n",
    "n_filters, ix = 32, 1\n",
    "\n",
    "for i in range(n_filters):    #32\n",
    "    f = filters[:, :, :, i]\n",
    "    for j in range(3):        #3 \n",
    "      ax = plt.subplot(gs[i,j])\n",
    "      ax.imshow(f[:, :, j], cmap='gray')\n",
    "      ax.set_xticklabels([])\n",
    "      ax.set_yticklabels([])\n",
    "\n",
    "plt.show()\n",
    "fig.savefig('layersconvolutional.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imageindex = 1\n",
    "image = visuvalizationtestimages[imageindex]\n",
    "img_test = np.expand_dims(image, axis=0)\n",
    "\n",
    "refinedneuralnet = tf.keras.models.Model([model.inputs],[model.get_layer(\"conv2d_4\").output])\n",
    "\n",
    "\n",
    "\n",
    "image = visuvalizationtestimages[imageindex]\n",
    "img_test = np.expand_dims(image, axis=0)\n",
    "\n",
    "plt.imshow(img_test[0])\n",
    "plt.title(\"True Label: \" + visuvalizationtruelabels[imageindex])\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "refinedneuralnet = tf.keras.models.Model([model.inputs],[model.get_layer(\"conv2d_4\").output])\n",
    "\n",
    "@tf.custom_gradient\n",
    "def guidedRelU(x):\n",
    "  def grad(dy):\n",
    "    return tf.cast(dy>0,\"float32\") * tf.cast(x>0, \"float32\") * dy\n",
    "  return tf.nn.relu(x), grad\n",
    "\n",
    "for layer in model.layers[1:]:\n",
    "    if hasattr(layer, 'activation') and layer.activation == tf.keras.activations.selu:\n",
    "        layer.activation = guidedRelU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape() as g:\n",
    "  inputs = tf.cast(img_test, tf.float32)\n",
    "  g.watch(inputs)\n",
    "  outputs = refinedneuralnet(inputs)[0]\n",
    "\n",
    "target_gradient = g.gradient(outputs,inputs)[0]\n",
    "\n",
    "CONV5_layer_activation = outputs\n",
    "layer_names = ['conv2d_4']\n",
    "num_features = 10\n",
    "size = 1\n",
    "num_imag_in_row = 1\n",
    "num_cols = num_features // num_imag_in_row\n",
    "gridofimages = np.ones((size * num_cols, num_imag_in_row * size))\n",
    "\n",
    "k = 1\n",
    "j = 1\n",
    "for col in range(num_cols): \n",
    "  for row in range(num_imag_in_row):\n",
    "    channel_image = CONV5_layer_activation[j, k, col * num_imag_in_row + row]\n",
    "    gridofimages[col * size : (col + 1) * size, row * size : (row + 1) * size] = channel_image\n",
    "  \n",
    "scale = 1. / size\n",
    "plt.figure(figsize=(scale * gridofimages.shape[1], scale * gridofimages.shape[0]))\n",
    "plt.title(layer_names)\n",
    "plt.grid(False)\n",
    "plt.imshow(gridofimages, aspect='auto',cmap='gray')  \n",
    "plt.show()                                         \n",
    "fig.savefig('neuronfire.png')\n",
    "\n",
    "gradientimage = np.dstack((\n",
    "            target_gradient[:, :, 0],\n",
    "            target_gradient[:, :, 1],\n",
    "            target_gradient[:, :, 2],\n",
    "        ))       \n",
    "\n",
    "gradientimage = gradientimage - np.min(gradientimage)\n",
    "gradientimage = gradientimage/gradientimage.max()\n",
    "imgplot = plt.imshow(gradientimage)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "fig.savefig('gradients.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# The shape of the layer that we are interested in\n",
    "conv_output_shape = model.layers[-8].output.shape[1:]\n",
    "\n",
    "plt.figure(figsize=(30, 60))\n",
    "for i in range(10):\n",
    "    # Index of a random pixel\n",
    "    Nx = np.random.randint(0, conv_output_shape[0])\n",
    "    Ny = np.random.randint(0, conv_output_shape[1])\n",
    "    Nz = np.random.randint(0, conv_output_shape[2])\n",
    "\n",
    "    # Mask to focus on the outputs of only one neuron in the last convolution layer\n",
    "    mat = np.zeros((1, *conv_output_shape), dtype=\"float\")\n",
    "    mat[0, Nx, Ny, Nz] = 1\n",
    "\n",
    "    # Calculate the gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        inputs = tf.cast(np.array([np.array(img)]), tf.float32)\n",
    "        tape.watch(inputs)\n",
    "        outputs = refinedneuralnet(inputs) * mat\n",
    "\n",
    "    grads = tape.gradient(outputs, inputs)[0]\n",
    "\n",
    "    # Visualize the output of guided backpropagation\n",
    "    imgguidedbp = np.dstack((grads[:, :, 0], grads[:, :, 1], grads[:, :, 2],)) \n",
    "\n",
    "    # Scaling to 0-1      \n",
    "    imgguidedbp = imgguidedbp - np.min(imgguidedbp)\n",
    "    imgguidedbp /= imgguidedbp.max()\n",
    "    plt.subplot(10, 1, i+1)\n",
    "    plt.imshow(imgguidedbp)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
